{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Hackathon_3_Guide.ipynb","version":"0.3.2","provenance":[{"file_id":"1SQTu9CnGFQIw0GhKFTF6w4M9q3XA1VT7","timestamp":1559879866185}],"collapsed_sections":[],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SZIubkln0AI2"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"code","metadata":{"id":"hA54nM_TqYyL","colab_type":"code","cellView":"form","outputId":"75892060-da0c-4a04-8201-cc9ec996ed15","colab":{"base_uri":"https://localhost:8080/","height":321}},"source":["#@title Experiment Explanation Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"500\" height=\"300\" controls>\n","  <source src=\"https://cdn.talentsprint.com/aiml/AIML_BATCH_HYD_7/Apr15/HackathonTaskArchitecture.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<video width=\"500\" height=\"300\" controls>\n","  <source src=\"https://cdn.talentsprint.com/aiml/AIML_BATCH_HYD_7/Apr15/HackathonTaskArchitecture.mp4\" type=\"video/mp4\">\n","</video>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4LNbxek40AI4"},"source":["# Hackathon 3: Anti Face Spoofing"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3e0e3sFh0JZJ"},"source":["### Setup Steps"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xWQwfHmR0MDu","colab":{}},"source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"P181902118\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RBdFVMDi0Ou0","colab":{}},"source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"8860303743\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"both","colab_type":"code","id":"Kv0xxq_d0Qb_","outputId":"2de74407-67e7-46c2-bd46-b3e19cc5ddcd","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1559965586729,"user_tz":-330,"elapsed":157299,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"source":["#@title Run this cell to complete the setup for this Notebook\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"M2_Hackathon\" #name of the notebook\n","\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/FaceRecogHackathon/Datasets/IMFDB_face_recog/IMFDB_final-20190607T024441Z-001.zip\")\n","    ipython.magic(\"sx wget wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Expression_data.zip\")\n","    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/FaceRecogHackathon/Datasets/ATandT/data-20190607T005435Z-001.zip\")\n","    ipython.magic(\"sx unzip IMFDB_final-20190607T024441Z-001.zip\")\n","    ipython.magic(\"sx unzip Expression_data.zip\")\n","    ipython.magic(\"sx unzip data-20190607T005435Z-001.zip\")\n","    ipython.magic(\"sx pip install torch==1.0.1 -f https://download.pytorch.org/whl/cu100/stable\")\n","    ipython.magic(\"sx pip install torchvision==0.2.1\")\n","    ipython.magic(\"sx pip install opencv-python\")\n","    print (\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      print(\"Your submission is successful. Ref:\", submission_id)\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DqNBNvC25WNV","colab":{}},"source":["import torch\n","from torch.autograd import Variable\n","import numpy as np\n","import os\n","import warnings\n","from time import sleep\n","import sys\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wqMmxLR38vJ3"},"source":["##Data Collection\n","\n","* Using the Mobile Application, please collect the Faces and Expression data of your team. \n","* These will be stored in the Server to which login is provided to you.\n","* Download the data into your colab server using the downloadable link provided to you\n","* This data will be usefull training the networks\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NhLFY4n6BwIj"},"source":["##Data used: Indian Movie Face database (IMFDB)\n","It is a large unconstrained face database of images of 100 Indian actors collected from more than 100 videos. All the images are manually selected and cropped from the video frames resulting in a high degree of variability interms of scale, pose, expression, illumination, age, resolution, occlusion, and makeup\n","\n","During the setup you have downloaded this data:\n","\n","* **IMFDB_final**: This folder contains the face images segregrated by the actor in each folder\n","\n","\n","> * Each class is organised as one folder\n","\n","\n","* **Expression_data**: In this folder, the same images are segregrated in terms of Expression\n","> * Expressions available: ANGER, DISGUST, FEAR, HAPPINESS, NEUTRAL, SADNESS, SURPRISE\n","> * Each class is organised as one folder\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"B4-clpEl-1RF","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"e5ae642f-f56b-4dd3-d0ed-ae02eb39174b","executionInfo":{"status":"ok","timestamp":1559967852858,"user_tz":-330,"elapsed":2571,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"source":["%ls"],"execution_count":7,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/                          IMFDB_final-20190607T024441Z-001.zip\n","data-20190607T005435Z-001.zip  M2_Hackathon.ipynb\n","\u001b[01;34mExpression_data\u001b[0m/               \u001b[01;34m__MACOSX\u001b[0m/\n","Expression_data.zip            \u001b[01;34msample_data\u001b[0m/\n","\u001b[01;34mIMFDB_final\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bHpqJDuFHVmL"},"source":["###Download your data using the links provided to you"]},{"cell_type":"markdown","metadata":{"id":"6CxIHzcDbGJ4","colab_type":"text"},"source":["#### NOTE: Replace the string \"username\" with your team name (such as b7h3gxx) in both the cells below"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g6AlHmHNIdw3","colab":{}},"source":["!wget -nH --recursive --no-parent --reject 'index.*' https://aiml-sandbox.talentsprint.com/expression_detection/username/captured_face_images/ --cut-dirs=3  -P ./captured_face_images\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"I8U0F_CDIhmh","colab":{}},"source":["!wget -nH --recursive --no-parent --reject 'index.*' https://aiml-sandbox.talentsprint.com/expression_detection/username/captured_images_with_Expression/ --cut-dirs=3  -P ./captured_images_with_Expression"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sneRrCAeImPg"},"source":["Once downloaded using 'mv', please add the data into the respective folders IMFDB_final"]},{"cell_type":"code","metadata":{"id":"loev6InFaa1F","colab_type":"code","colab":{}},"source":["%ls"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SB-LowDuCMUL"},"source":["##Stage 1 (Face Recognition): (20 marks) \n","\n","* From the provided AT&T Faces data or IMFDB data train the Siamese network.\n","** If you're using the AT&T faces dataset, you are recommended to following the Siamese blog post provided to you last week as the starter code. (Its recommended you quickly try this approach before (if at all) trying the next IMFDB approach) Link [here](https://drive.google.com/open?id=17-hLbZgwgHFMKXHhrDwzWv42fXELMPkn)\n","** If you're however planning to use IMFDB data, the [ME40_siamese.ipynb](https://drive.google.com/open?id=1bav8yQF28v5rPoM5PbEIE13sPce8SA0K) is recommended as the starter code; Here select any ten celebrity face images (100 classes is too big) and add one of your team member’s data (11th celebrity :p ) using the mobile app.\n","\n","* Define and train a Siamese network\n","\n","* Save the state dictionary of the Siamese network (use pytorch only), It will be useful in\n","integrating to the mobile app\n","\n","* Define and train a classifier which takes output from the above trained Siamese network\n","(feature extraction network) as input to classify the above 11 classes\n","\n","* Save the state dictionary of the classifier (use pytorch only), It will be useful in\n","integrating to the mobile app\n","\n","* “face_recognition.py” routine in the server contains the necessary skeleton, integrate your model in\n","this to predict the face and to get similarity measure.(Note: To define the architecture of your trained model, you'll need to define it in the file \"face_recognition_model.py\")\n","\n","* .Upload your files to the given ftp server and test your model on the mobile app\n","\n","* . **Grading Scheme:**\n","\n","\n","> * Face Similarity (10M): The face similarity should close similar faces and should be\n","distant for dissimilar faces using the mobile app’s “Face Similarity” functionality\n","\n","\n","> * Face Recognition (10M): Recognize the person correctly using the mobile app’s “Face Recognition” functionality"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CE__iTELMolD"},"source":["####Save your model\n","\n","* Save the state dictionary of the classifier (use pytorch only), It will be useful in\n","integrating model to the mobile app"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"V2zKlpz_MzY1"},"source":["#### Download your trained model using the code below\n","* given the path of model file the following code downloads it through the browser"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R7LaIqCDMzY5","colab":{}},"source":["from google.colab import files\n","files.download('<model_file_path>')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BGq6XpvhFynP"},"source":["##Stage 2 (Expression Recognition): (20 marks)\n","* Define and train a CNN for expression recognition with the given IMFDB data segregated\n","on expression basis.\n","* Collect your data using mobiledata and fine-tune the CNN for expression data on your team\n","* “exp_recognition.py” routine contains the necessary skeleton, integrate your model to predict the expression on the face (Note: To define the architecture of your trained model, you'll need to define it in the file \"exp_recognition_model.py\")\n","* Upload your files to the given ftp server and test your model on the mobile app\n","* Grading Scheme:\n","> * Expression Recognition (10M): If the functionality of giving back an expression\n","class for the face using the mobile app’s “Expression Recognition” functionality\n","> * Sequence Expression (10M): Get three consecutive correct Expressions using the\n","mobile app’s “Sequence Expressions” functionality"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VU5hdERsFw5o","colab":{}},"source":["##YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OGixO_z6Gf-Y"},"source":["####Save your model\n","\n","* Save the state dictionary of the classifier (use pytorch only), It will be useful in\n","integrating model to the mobile app"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jsCHKXubHAJB"},"source":["#### Download your trained model using the code below\n","* given the path of model file the following code downloads it through the browser"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BDmWXfPaHJZG","colab":{}},"source":["from google.colab import files\n","files.download('<model_file_path>')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"R7ccsM_ZISWj"},"source":["\n","***Stage 3 (Anti Face Spoofing): (10 marks)***\n","The objective of anti-spoofing, is to be able to unlock (say) a screen not just by your image\n","(which can be easily be spoofed with a photograph of yours) but by a switch in the expression\n","demanded by the Mobile App (which is much less probable to mimic)\n","* **Grading scheme**:\n","> * **Anti Face Spoofing**: (10M Only if both the cases mentioned below are achieved)\n",">>* **Unlock**: Correct face + Correct Demanded Expression\n",">>* **Stay Locked**: Correct face + Incorrect Demanded Expression (as you might imagine there are multiple other such possibilities, which you are free to explore)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zQhiuXMaMRp2"},"source":["### Deployment instruction are given the Hackathon documentation"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jx6Y0Roy19a0"},"source":["### Please answer the questions below to complete the experiment:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-O68_f5E2Az_","colab":{}},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4YpxQ61Q2CjX","colab":{}},"source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"\" #@param {type:\"string\"}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QZWB9A6M2Fuv","colab":{}},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"\" #@param [\"Yes\", \"No\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","colab_type":"code","id":"03H962QV2Haz","colab":{}},"source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":0,"outputs":[]}]}