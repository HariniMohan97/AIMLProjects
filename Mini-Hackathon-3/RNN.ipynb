{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vuGTbnJqMZvg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":587},"outputId":"36a5a1c6-1f46-45c8-f008-43c8438ea5e6","executionInfo":{"status":"ok","timestamp":1559361661424,"user_tz":-330,"elapsed":39831,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"source":["!pip3 install kaggle\n","from googleapiclient.discovery import build\n","import io, os\n","from googleapiclient.http import MediaIoBaseDownload\n","from google.colab import auth\n","auth.authenticate_user()\n","drive_service = build('drive', 'v3')\n","results = drive_service.files().list(\n","q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n","kaggle_api_key = results.get('files', [])\n","filename = \"content/kaggle.json\"\n","os.makedirs(os.path.dirname(filename), exist_ok=True)\n","request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n","fh = io.FileIO(filename, 'wb')\n","downloader = MediaIoBaseDownload(fh, request)\n","done = False\n","while done is False:\n","  status, done = downloader.next_chunk()\n","  print(\"Download %d%%.\" % int(status.progress() * 100))\n","os.chmod(filename, 600)\n","\n","\n","!mkdir ~/.kaggle\n","!cp /content/content/kaggle.json ~/.kaggle/kaggle.json\n","\n","!mkdir data\n","!kaggle competitions download -c retail-case-study-b7 -p data"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.4)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n","Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n","Download 100%.\n","Downloading WeatherData.xlsx to data\n","  0% 0.00/329k [00:00<?, ?B/s]\n","100% 329k/329k [00:00<00:00, 43.8MB/s]\n","Downloading Train_Kaggle.csv to data\n","  0% 0.00/5.31k [00:00<?, ?B/s]\n","100% 5.31k/5.31k [00:00<00:00, 4.42MB/s]\n","Downloading Test_Kaggle.csv to data\n","  0% 0.00/793 [00:00<?, ?B/s]\n","100% 793/793 [00:00<00:00, 584kB/s]\n","Downloading Sample_Submission.csv to data\n","  0% 0.00/309 [00:00<?, ?B/s]\n","100% 309/309 [00:00<00:00, 283kB/s]\n","Downloading MacroEconomicData.xlsx to data\n","  0% 0.00/17.4k [00:00<?, ?B/s]\n","100% 17.4k/17.4k [00:00<00:00, 15.4MB/s]\n","Downloading Events_HolidaysData.xlsx to data\n","  0% 0.00/12.4k [00:00<?, ?B/s]\n","100% 12.4k/12.4k [00:00<00:00, 12.0MB/s]\n","Downloading AttributesDescription.xlsx to data\n","  0% 0.00/10.2k [00:00<?, ?B/s]\n","100% 10.2k/10.2k [00:00<00:00, 10.8MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PNqkz-yRMf3w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":207},"outputId":"881693b2-b585-4832-a8f8-ad95c0b78169","executionInfo":{"status":"ok","timestamp":1559361916804,"user_tz":-330,"elapsed":7974,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"source":["!mkdir ../input/\n","!kaggle competitions download -c retail-case-study-b7 -p ../input/\n","!ls data"],"execution_count":3,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘../input/’: File exists\n","WeatherData.xlsx: Skipping, found more recently modified local copy (use --force to force download)\n","Train_Kaggle.csv: Skipping, found more recently modified local copy (use --force to force download)\n","Test_Kaggle.csv: Skipping, found more recently modified local copy (use --force to force download)\n","Sample_Submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n","MacroEconomicData.xlsx: Skipping, found more recently modified local copy (use --force to force download)\n","Events_HolidaysData.xlsx: Skipping, found more recently modified local copy (use --force to force download)\n","AttributesDescription.xlsx: Skipping, found more recently modified local copy (use --force to force download)\n","AttributesDescription.xlsx  Sample_Submission.csv  WeatherData.xlsx\n","Events_HolidaysData.xlsx    Test_Kaggle.csv\n","MacroEconomicData.xlsx\t    Train_Kaggle.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7CyNgL0bMhnm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"fac11b13-c4bd-4e24-88be-d2fe28db8596","executionInfo":{"status":"ok","timestamp":1559365332729,"user_tz":-330,"elapsed":886,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","%matplotlib inline\n","\n","import math, time, random, datetime\n","\n","# Data Manipulation\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Visualisation\n","import matplotlib.pyplot as plt\n","import missingno\n","import seaborn as sns\n","plt.style.use('seaborn-whitegrid')\n","\n","# Preprocessing\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n","\n","# Machine Learning\n","from sklearn.model_selection import train_test_split\n","from sklearn import model_selection, tree, preprocessing, metrics, linear_model\n","from sklearn.svm import LinearSVC\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","\n","## Importing required packages\n","import string\n","import random\n","import re\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import os\n","\n","\n","# Lets ignore the warnings for now\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# for RNN\n","import string\n","import random\n","import re\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","\n","print(os.listdir(\"../input\"))\n","\n","trainPD = pd.read_csv('../input/Train_Kaggle.csv')\n","testPD  = pd.read_csv('../input/Test_Kaggle.csv')\n","sampleSubPD  = pd.read_csv('../input/Sample_Submission.csv')\n","\n","attDescPD = pd.read_excel('../input/AttributesDescription.xlsx')\n","eventHolidaysPD = pd.read_excel('../input/Events_HolidaysData.xlsx')\n","macroEconomicsPD = pd.read_excel('../input/MacroEconomicData.xlsx')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["['Train_Kaggle.csv', 'Test_Kaggle.csv', 'Events_HolidaysData.xlsx', 'WeatherData.xlsx', 'Sample_Submission.csv', 'MacroEconomicData.xlsx', 'AttributesDescription.xlsx']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JoViIOFXOGNm","colab_type":"code","colab":{}},"source":["### Creating recurrent neural network\n","class RNN(nn.Module):\n","    \n","    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n","        super(RNN, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.encoder = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n","        self.decoder = nn.Linear(hidden_size, output_size)\n","    \n","    def forward(self, input, hidden):\n","        input = self.encoder(input.view(1, -1))\n","        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n","        output = self.decoder(output.view(1, -1))\n","        return output, hidden\n","\n","    def init_hidden(self):\n","        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmeppg3sQmbV","colab_type":"code","colab":{}},"source":["def train(inp, target):\n","    hidden = decoder.init_hidden()\n","    decoder.zero_grad()\n","    loss = 0\n","\n","    for c in range(chunk_len):\n","        output, hidden = decoder(inp[c], hidden)\n","        '''unsqueeze() is used to add dimension to the tensor'''\n","        loss += criterion(output, target[c].unsqueeze(dim=0))\n","    # Back propagation\n","    loss.backward()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / chunk_len"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FkfePbdjVoIY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-O3heGXyVoKs","colab_type":"code","colab":{}},"source":["all_characters = string.printable\n","# Turn string into list of longs\n","def char_tensor(string):\n","    ##  tensor is a array\n","    tensor = torch.zeros(len(string)).long()\n","    for c in range(len(string)):\n","        tensor[c] = all_characters.index(string[c])\n","    return Variable(tensor)\n","\n","print(char_tensor('abcDEF'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S1CceXLpShgt","colab_type":"code","colab":{}},"source":["def get_training_set(trainPD):    \n","    chunk = random_chunk()\n","    inp = char_tensor(chunk[:-1])\n","    target = char_tensor(chunk[1:])\n","    return inp, target"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-LYRQSlNQmdk","colab_type":"code","colab":{}},"source":["n_epochs = 2000 #Number of epochs\n","print_every = 50\n","plot_every = 20\n","hidden_size = 100\n","n_layers = 1\n","lr = 0.005\n","\n","decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n","## Optimizer\n","decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n","## Loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","start = time.time()\n","all_losses = []\n","loss_avg = 0\n","\n","for epoch in range(1, n_epochs + 1):\n","    loss = train(*get_training_set())       \n","    loss_avg += loss\n","\n","    if epoch % print_every == 0:\n","        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n","        print(evaluate('Wh', 100), '\\n')\n","\n","    if epoch % plot_every == 0:\n","        all_losses.append(loss_avg / plot_every)\n","        loss_avg = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mZh313qrQmfk","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","%matplotlib inline\n","\n","plt.figure()\n","plt.plot(all_losses)\n","plt.xlabel(\"epoch\")\n","plt.ylabel(\"loss\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SGuMC-UjQmiu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}